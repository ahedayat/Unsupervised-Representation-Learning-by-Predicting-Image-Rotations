################################
Namespace(backbone='resnet34'
 batch_size=1024
 ckpt_load_path='./checkpoints/rotation_final.ckpt'
 ckpt_prefix='classification'
 ckpt_save_freq=20
 ckpt_save_path='./checkpoints_classification'
 feature_layer_index=3
 gpu=True
 lr=0.001
 momentum=0.9
 num_epochs=100
 num_workers=2
 optimizer='adam'
 report_path='./reports_classification_not_all_3'
 show_all_angles=False
 shuffle_data=False
 test_data_path='./datasets/cifar10'
 train_data_path='/content/datasets/cifar10'
 val_data_path='/content/datasets/cifar10'
 weight_decay=0.0005)
################################
Files already downloaded and verified
Files already downloaded and verified
Files already downloaded and verified
Loading './checkpoints/rotation_final.ckpt'
Model is loaded successfully.
MyResNet34(
  (backbone): ResNet(
    (conv1): Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)
    (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (relu): ReLU(inplace=True)
    (maxpool): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)
    (layer1): Sequential(
      (0): BasicBlock(
        (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (relu): ReLU(inplace=True)
        (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (1): BasicBlock(
        (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (relu): ReLU(inplace=True)
        (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (2): BasicBlock(
        (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (relu): ReLU(inplace=True)
        (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
    )
    (layer2): Sequential(
      (0): BasicBlock(
        (conv1): Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
        (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (relu): ReLU(inplace=True)
        (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (downsample): Sequential(
          (0): Conv2d(64, 128, kernel_size=(1, 1), stride=(2, 2), bias=False)
          (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
      )
      (1): BasicBlock(
        (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (relu): ReLU(inplace=True)
        (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (2): BasicBlock(
        (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (relu): ReLU(inplace=True)
        (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (3): BasicBlock(
        (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (relu): ReLU(inplace=True)
        (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
    )
    (layer3): Sequential(
      (0): BasicBlock(
        (conv1): Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (relu): ReLU(inplace=True)
        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (downsample): Sequential(
          (0): Conv2d(128, 256, kernel_size=(1, 1), stride=(2, 2), bias=False)
          (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
      )
      (1): BasicBlock(
        (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (relu): ReLU(inplace=True)
        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (2): BasicBlock(
        (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (relu): ReLU(inplace=True)
        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (3): BasicBlock(
        (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (relu): ReLU(inplace=True)
        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (4): BasicBlock(
        (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (relu): ReLU(inplace=True)
        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (5): BasicBlock(
        (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (relu): ReLU(inplace=True)
        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
    )
    (layer4): Identity()
    (avgpool): AdaptiveAvgPool2d(output_size=(1, 1))
    (fc): Identity()
  )
  (my_classifier): Sequential(
    (0): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (1): Linear(in_features=256, out_features=128, bias=True)
    (2): Dropout(p=0.2, inplace=True)
    (3): Linear(in_features=128, out_features=64, bias=True)
    (4): Dropout(p=0.2, inplace=True)
    (5): Linear(in_features=64, out_features=10, bias=True)
  )
)
Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    eps: 1e-08
    lr: 0.001
    maximize: False
    weight_decay: 0.0005
)
Training Classifier @ Epoch 0: 100% 43/43 [00:08<00:00,  5.33it/s, acc1=41.436, acc2=63.558, loss=1.606, lr=1.00000e-03]
Evaluation Classifier @ Epoch 0: 100% 4/4 [00:00<00:00,  4.20it/s, acc1=51.562, acc2=74.878, loss=1.488]
Training Classifier @ Epoch 1: 100% 43/43 [00:08<00:00,  5.33it/s, acc1=53.052, acc2=75.561, loss=1.272, lr=1.00000e-03]
Evaluation Classifier @ Epoch 1: 100% 4/4 [00:00<00:00,  4.16it/s, acc1=56.274, acc2=78.076, loss=1.182]
Training Classifier @ Epoch 2: 100% 43/43 [00:08<00:00,  5.35it/s, acc1=56.404, acc2=77.544, loss=1.201, lr=1.00000e-03]
Evaluation Classifier @ Epoch 2: 100% 4/4 [00:00<00:00,  4.16it/s, acc1=58.618, acc2=79.272, loss=1.126]
Training Classifier @ Epoch 3: 100% 43/43 [00:08<00:00,  5.32it/s, acc1=57.722, acc2=78.289, loss=1.169, lr=1.00000e-03]
Evaluation Classifier @ Epoch 3: 100% 4/4 [00:00<00:00,  4.30it/s, acc1=59.717, acc2=79.932, loss=1.105]
Training Classifier @ Epoch 4: 100% 43/43 [00:08<00:00,  5.27it/s, acc1=58.517, acc2=78.893, loss=1.147, lr=1.00000e-03]
Evaluation Classifier @ Epoch 4: 100% 4/4 [00:00<00:00,  4.08it/s, acc1=60.083, acc2=79.907, loss=1.093]
Training Classifier @ Epoch 5: 100% 43/43 [00:08<00:00,  5.32it/s, acc1=59.470, acc2=79.517, loss=1.126, lr=1.00000e-04]
Evaluation Classifier @ Epoch 5: 100% 4/4 [00:00<00:00,  4.23it/s, acc1=60.840, acc2=80.322, loss=1.080]
Training Classifier @ Epoch 6: 100% 43/43 [00:08<00:00,  5.35it/s, acc1=59.629, acc2=79.379, loss=1.122, lr=1.00000e-04]
Evaluation Classifier @ Epoch 6: 100% 4/4 [00:00<00:00,  4.09it/s, acc1=60.522, acc2=80.322, loss=1.079]
Training Classifier @ Epoch 7: 100% 43/43 [00:08<00:00,  5.28it/s, acc1=59.582, acc2=79.526, loss=1.120, lr=1.00000e-04]
Evaluation Classifier @ Epoch 7: 100% 4/4 [00:00<00:00,  4.02it/s, acc1=60.767, acc2=80.249, loss=1.078]
Training Classifier @ Epoch 8: 100% 43/43 [00:08<00:00,  5.34it/s, acc1=59.645, acc2=79.635, loss=1.120, lr=1.00000e-04]
Evaluation Classifier @ Epoch 8: 100% 4/4 [00:00<00:00,  4.27it/s, acc1=60.938, acc2=80.566, loss=1.076]
Training Classifier @ Epoch 9: 100% 43/43 [00:08<00:00,  5.35it/s, acc1=60.022, acc2=79.651, loss=1.115, lr=1.00000e-05]
Evaluation Classifier @ Epoch 9: 100% 4/4 [00:00<00:00,  4.26it/s, acc1=60.791, acc2=80.518, loss=1.076]
Training Classifier @ Epoch 10: 100% 43/43 [00:08<00:00,  5.35it/s, acc1=59.763, acc2=79.610, loss=1.118, lr=1.00000e-05]
Evaluation Classifier @ Epoch 10: 100% 4/4 [00:00<00:00,  4.19it/s, acc1=60.889, acc2=80.542, loss=1.076]
Training Classifier @ Epoch 11: 100% 43/43 [00:08<00:00,  5.28it/s, acc1=59.793, acc2=79.799, loss=1.115, lr=1.00000e-05]
Evaluation Classifier @ Epoch 11: 100% 4/4 [00:00<00:00,  4.16it/s, acc1=60.962, acc2=80.566, loss=1.075]
Training Classifier @ Epoch 12: 100% 43/43 [00:08<00:00,  5.30it/s, acc1=59.959, acc2=79.565, loss=1.116, lr=1.00000e-05]
Evaluation Classifier @ Epoch 12: 100% 4/4 [00:00<00:00,  4.14it/s, acc1=60.962, acc2=80.518, loss=1.075]
Training Classifier @ Epoch 13: 100% 43/43 [00:08<00:00,  5.36it/s, acc1=59.956, acc2=79.667, loss=1.117, lr=1.00000e-06]
Evaluation Classifier @ Epoch 13: 100% 4/4 [00:01<00:00,  3.99it/s, acc1=60.767, acc2=80.518, loss=1.075]
Training Classifier @ Epoch 14: 100% 43/43 [00:08<00:00,  5.28it/s, acc1=59.872, acc2=79.783, loss=1.118, lr=1.00000e-06]
Evaluation Classifier @ Epoch 14: 100% 4/4 [00:01<00:00,  4.00it/s, acc1=60.840, acc2=80.640, loss=1.075]
Training Classifier @ Epoch 15: 100% 43/43 [00:08<00:00,  5.30it/s, acc1=59.972, acc2=79.617, loss=1.117, lr=1.00000e-06]
Evaluation Classifier @ Epoch 15: 100% 4/4 [00:00<00:00,  4.05it/s, acc1=60.815, acc2=80.493, loss=1.075]
Training Classifier @ Epoch 16: 100% 43/43 [00:08<00:00,  5.31it/s, acc1=59.900, acc2=79.567, loss=1.115, lr=1.00000e-06]
Evaluation Classifier @ Epoch 16: 100% 4/4 [00:00<00:00,  4.24it/s, acc1=60.815, acc2=80.469, loss=1.075]
Training Classifier @ Epoch 17: 100% 43/43 [00:08<00:00,  5.34it/s, acc1=59.854, acc2=79.658, loss=1.117, lr=1.00000e-06]
Evaluation Classifier @ Epoch 17: 100% 4/4 [00:00<00:00,  4.32it/s, acc1=60.791, acc2=80.518, loss=1.075]
Training Classifier @ Epoch 18: 100% 43/43 [00:08<00:00,  5.30it/s, acc1=59.947, acc2=79.799, loss=1.117, lr=1.00000e-06]
Evaluation Classifier @ Epoch 18: 100% 4/4 [00:00<00:00,  4.18it/s, acc1=60.767, acc2=80.493, loss=1.076]
Training Classifier @ Epoch 19: 100% 43/43 [00:08<00:00,  5.32it/s, acc1=60.129, acc2=79.624, loss=1.115, lr=1.00000e-06]
Evaluation Classifier @ Epoch 19: 100% 4/4 [00:00<00:00,  4.12it/s, acc1=60.767, acc2=80.615, loss=1.075]
(Epoch: 19) > Model Saved.
Training Classifier @ Epoch 20: 100% 43/43 [00:08<00:00,  5.28it/s, acc1=59.913, acc2=79.547, loss=1.117, lr=1.00000e-06]
Evaluation Classifier @ Epoch 20: 100% 4/4 [00:00<00:00,  4.08it/s, acc1=60.889, acc2=80.566, loss=1.075]
Training Classifier @ Epoch 21: 100% 43/43 [00:08<00:00,  5.37it/s, acc1=59.795, acc2=79.522, loss=1.119, lr=1.00000e-06]
Evaluation Classifier @ Epoch 21: 100% 4/4 [00:00<00:00,  4.14it/s, acc1=60.913, acc2=80.591, loss=1.075]
Training Classifier @ Epoch 22: 100% 43/43 [00:07<00:00,  5.41it/s, acc1=59.872, acc2=79.663, loss=1.116, lr=1.00000e-06]
Evaluation Classifier @ Epoch 22: 100% 4/4 [00:00<00:00,  4.17it/s, acc1=60.669, acc2=80.615, loss=1.075]
Training Classifier @ Epoch 23: 100% 43/43 [00:08<00:00,  5.32it/s, acc1=59.916, acc2=79.874, loss=1.112, lr=1.00000e-06]
Evaluation Classifier @ Epoch 23: 100% 4/4 [00:00<00:00,  4.16it/s, acc1=60.767, acc2=80.493, loss=1.075]
Training Classifier @ Epoch 24: 100% 43/43 [00:08<00:00,  5.31it/s, acc1=59.827, acc2=79.901, loss=1.116, lr=1.00000e-06]
Evaluation Classifier @ Epoch 24: 100% 4/4 [00:00<00:00,  4.04it/s, acc1=60.767, acc2=80.566, loss=1.075]
Training Classifier @ Epoch 25: 100% 43/43 [00:08<00:00,  5.33it/s, acc1=59.861, acc2=79.742, loss=1.118, lr=1.00000e-06]
Evaluation Classifier @ Epoch 25: 100% 4/4 [00:00<00:00,  4.08it/s, acc1=60.815, acc2=80.542, loss=1.075]
Training Classifier @ Epoch 26: 100% 43/43 [00:08<00:00,  5.31it/s, acc1=59.975, acc2=79.672, loss=1.115, lr=1.00000e-06]
Evaluation Classifier @ Epoch 26: 100% 4/4 [00:00<00:00,  4.19it/s, acc1=60.962, acc2=80.542, loss=1.075]
Training Classifier @ Epoch 27: 100% 43/43 [00:08<00:00,  5.32it/s, acc1=59.950, acc2=79.751, loss=1.114, lr=1.00000e-06]
Evaluation Classifier @ Epoch 27: 100% 4/4 [00:00<00:00,  4.20it/s, acc1=60.718, acc2=80.640, loss=1.075]
Training Classifier @ Epoch 28: 100% 43/43 [00:08<00:00,  5.31it/s, acc1=59.986, acc2=79.617, loss=1.113, lr=1.00000e-06]
Evaluation Classifier @ Epoch 28: 100% 4/4 [00:00<00:00,  4.13it/s, acc1=60.767, acc2=80.493, loss=1.075]
Training Classifier @ Epoch 29: 100% 43/43 [00:07<00:00,  5.39it/s, acc1=59.886, acc2=79.985, loss=1.114, lr=1.00000e-06]
Evaluation Classifier @ Epoch 29: 100% 4/4 [00:00<00:00,  4.23it/s, acc1=60.913, acc2=80.566, loss=1.075]
Training Classifier @ Epoch 30: 100% 43/43 [00:08<00:00,  5.35it/s, acc1=59.938, acc2=79.669, loss=1.115, lr=1.00000e-06]
Evaluation Classifier @ Epoch 30: 100% 4/4 [00:00<00:00,  4.07it/s, acc1=60.718, acc2=80.469, loss=1.075]
Training Classifier @ Epoch 31: 100% 43/43 [00:08<00:00,  5.33it/s, acc1=59.947, acc2=79.540, loss=1.118, lr=1.00000e-06]
Evaluation Classifier @ Epoch 31: 100% 4/4 [00:00<00:00,  4.02it/s, acc1=60.791, acc2=80.469, loss=1.075]
Training Classifier @ Epoch 32: 100% 43/43 [00:08<00:00,  5.26it/s, acc1=59.841, acc2=79.756, loss=1.116, lr=1.00000e-06]
Evaluation Classifier @ Epoch 32: 100% 4/4 [00:00<00:00,  4.08it/s, acc1=60.718, acc2=80.566, loss=1.075]
Training Classifier @ Epoch 33: 100% 43/43 [00:08<00:00,  5.25it/s, acc1=59.775, acc2=79.715, loss=1.115, lr=1.00000e-06]
Evaluation Classifier @ Epoch 33: 100% 4/4 [00:00<00:00,  4.06it/s, acc1=60.693, acc2=80.566, loss=1.075]
Training Classifier @ Epoch 34: 100% 43/43 [00:08<00:00,  5.26it/s, acc1=59.977, acc2=79.649, loss=1.114, lr=1.00000e-06]
Evaluation Classifier @ Epoch 34: 100% 4/4 [00:00<00:00,  4.15it/s, acc1=60.840, acc2=80.640, loss=1.075]
Training Classifier @ Epoch 35: 100% 43/43 [00:08<00:00,  5.29it/s, acc1=59.900, acc2=79.760, loss=1.115, lr=1.00000e-06]
Evaluation Classifier @ Epoch 35: 100% 4/4 [00:00<00:00,  4.05it/s, acc1=60.767, acc2=80.615, loss=1.075]
Training Classifier @ Epoch 36: 100% 43/43 [00:08<00:00,  5.37it/s, acc1=59.863, acc2=79.613, loss=1.115, lr=1.00000e-06]
Evaluation Classifier @ Epoch 36: 100% 4/4 [00:00<00:00,  4.23it/s, acc1=60.864, acc2=80.542, loss=1.075]
Training Classifier @ Epoch 37: 100% 43/43 [00:08<00:00,  5.30it/s, acc1=59.838, acc2=79.744, loss=1.115, lr=1.00000e-06]
Evaluation Classifier @ Epoch 37: 100% 4/4 [00:00<00:00,  4.07it/s, acc1=60.815, acc2=80.664, loss=1.074]
Training Classifier @ Epoch 38: 100% 43/43 [00:08<00:00,  5.29it/s, acc1=60.052, acc2=79.692, loss=1.114, lr=1.00000e-06]
Evaluation Classifier @ Epoch 38: 100% 4/4 [00:00<00:00,  4.13it/s, acc1=60.791, acc2=80.542, loss=1.075]
Training Classifier @ Epoch 39: 100% 43/43 [00:08<00:00,  5.32it/s, acc1=59.945, acc2=79.722, loss=1.114, lr=1.00000e-06]
Evaluation Classifier @ Epoch 39: 100% 4/4 [00:00<00:00,  4.08it/s, acc1=60.962, acc2=80.591, loss=1.075]
(Epoch: 39) > Model Saved.
Training Classifier @ Epoch 40: 100% 43/43 [00:08<00:00,  5.19it/s, acc1=59.788, acc2=79.454, loss=1.117, lr=1.00000e-06]
Evaluation Classifier @ Epoch 40: 100% 4/4 [00:00<00:00,  4.14it/s, acc1=60.767, acc2=80.615, loss=1.075]
Training Classifier @ Epoch 41: 100% 43/43 [00:08<00:00,  5.28it/s, acc1=59.886, acc2=79.542, loss=1.119, lr=1.00000e-06]
Evaluation Classifier @ Epoch 41: 100% 4/4 [00:00<00:00,  4.09it/s, acc1=60.962, acc2=80.566, loss=1.075]
Training Classifier @ Epoch 42: 100% 43/43 [00:08<00:00,  5.20it/s, acc1=59.945, acc2=79.663, loss=1.116, lr=1.00000e-06]
Evaluation Classifier @ Epoch 42: 100% 4/4 [00:01<00:00,  4.00it/s, acc1=60.791, acc2=80.469, loss=1.074]
Training Classifier @ Epoch 43: 100% 43/43 [00:08<00:00,  5.26it/s, acc1=59.920, acc2=79.801, loss=1.115, lr=1.00000e-06]
Evaluation Classifier @ Epoch 43: 100% 4/4 [00:00<00:00,  4.22it/s, acc1=60.889, acc2=80.615, loss=1.074]
Training Classifier @ Epoch 44: 100% 43/43 [00:08<00:00,  5.26it/s, acc1=59.963, acc2=79.840, loss=1.115, lr=1.00000e-06]
Evaluation Classifier @ Epoch 44: 100% 4/4 [00:00<00:00,  4.13it/s, acc1=60.815, acc2=80.542, loss=1.075]
Training Classifier @ Epoch 45: 100% 43/43 [00:08<00:00,  5.29it/s, acc1=59.816, acc2=79.719, loss=1.115, lr=1.00000e-06]
Evaluation Classifier @ Epoch 45: 100% 4/4 [00:00<00:00,  4.31it/s, acc1=60.840, acc2=80.591, loss=1.075]
Training Classifier @ Epoch 46: 100% 43/43 [00:08<00:00,  5.24it/s, acc1=59.988, acc2=79.862, loss=1.115, lr=1.00000e-06]
Evaluation Classifier @ Epoch 46: 100% 4/4 [00:00<00:00,  4.04it/s, acc1=60.864, acc2=80.591, loss=1.075]
Training Classifier @ Epoch 47: 100% 43/43 [00:08<00:00,  5.21it/s, acc1=60.233, acc2=79.769, loss=1.113, lr=1.00000e-06]
Evaluation Classifier @ Epoch 47: 100% 4/4 [00:00<00:00,  4.11it/s, acc1=60.815, acc2=80.444, loss=1.075]
Training Classifier @ Epoch 48: 100% 43/43 [00:08<00:00,  5.26it/s, acc1=59.979, acc2=79.633, loss=1.114, lr=1.00000e-06]
Evaluation Classifier @ Epoch 48: 100% 4/4 [00:00<00:00,  4.21it/s, acc1=60.815, acc2=80.615, loss=1.075]
Training Classifier @ Epoch 49: 100% 43/43 [00:08<00:00,  5.26it/s, acc1=59.709, acc2=79.533, loss=1.115, lr=1.00000e-06]
Evaluation Classifier @ Epoch 49: 100% 4/4 [00:00<00:00,  4.07it/s, acc1=60.815, acc2=80.420, loss=1.075]
Training Classifier @ Epoch 50: 100% 43/43 [00:08<00:00,  5.25it/s, acc1=59.870, acc2=79.803, loss=1.116, lr=1.00000e-06]
Evaluation Classifier @ Epoch 50: 100% 4/4 [00:01<00:00,  3.94it/s, acc1=60.693, acc2=80.591, loss=1.075]
Training Classifier @ Epoch 51: 100% 43/43 [00:08<00:00,  5.28it/s, acc1=59.925, acc2=79.799, loss=1.114, lr=1.00000e-06]
Evaluation Classifier @ Epoch 51: 100% 4/4 [00:00<00:00,  4.30it/s, acc1=60.889, acc2=80.396, loss=1.075]
Training Classifier @ Epoch 52: 100% 43/43 [00:08<00:00,  5.24it/s, acc1=59.922, acc2=79.828, loss=1.114, lr=1.00000e-06]
Evaluation Classifier @ Epoch 52: 100% 4/4 [00:00<00:00,  4.13it/s, acc1=60.938, acc2=80.347, loss=1.075]
Training Classifier @ Epoch 53: 100% 43/43 [00:08<00:00,  5.27it/s, acc1=60.115, acc2=79.783, loss=1.114, lr=1.00000e-06]
Evaluation Classifier @ Epoch 53: 100% 4/4 [00:00<00:00,  4.09it/s, acc1=60.962, acc2=80.566, loss=1.074]
Training Classifier @ Epoch 54: 100% 43/43 [00:08<00:00,  5.21it/s, acc1=59.843, acc2=79.737, loss=1.116, lr=1.00000e-06]
Evaluation Classifier @ Epoch 54: 100% 4/4 [00:00<00:00,  4.16it/s, acc1=60.718, acc2=80.420, loss=1.075]
Training Classifier @ Epoch 55: 100% 43/43 [00:08<00:00,  5.23it/s, acc1=59.897, acc2=79.737, loss=1.117, lr=1.00000e-06]
Evaluation Classifier @ Epoch 55: 100% 4/4 [00:00<00:00,  4.12it/s, acc1=60.815, acc2=80.591, loss=1.075]
Training Classifier @ Epoch 56: 100% 43/43 [00:08<00:00,  5.26it/s, acc1=59.822, acc2=79.733, loss=1.117, lr=1.00000e-06]
Evaluation Classifier @ Epoch 56: 100% 4/4 [00:00<00:00,  4.12it/s, acc1=60.767, acc2=80.542, loss=1.075]
Training Classifier @ Epoch 57: 100% 43/43 [00:08<00:00,  5.23it/s, acc1=60.211, acc2=79.656, loss=1.116, lr=1.00000e-06]
Evaluation Classifier @ Epoch 57: 100% 4/4 [00:00<00:00,  4.01it/s, acc1=60.767, acc2=80.518, loss=1.075]
Training Classifier @ Epoch 58: 100% 43/43 [00:08<00:00,  5.20it/s, acc1=59.845, acc2=79.797, loss=1.113, lr=1.00000e-06]
Evaluation Classifier @ Epoch 58: 100% 4/4 [00:01<00:00,  3.98it/s, acc1=60.791, acc2=80.664, loss=1.074]
Training Classifier @ Epoch 59: 100% 43/43 [00:08<00:00,  5.22it/s, acc1=60.090, acc2=79.672, loss=1.115, lr=1.00000e-06]
Evaluation Classifier @ Epoch 59: 100% 4/4 [00:00<00:00,  4.01it/s, acc1=60.742, acc2=80.542, loss=1.074]
(Epoch: 59) > Model Saved.
Training Classifier @ Epoch 60: 100% 43/43 [00:08<00:00,  5.11it/s, acc1=60.043, acc2=79.592, loss=1.117, lr=1.00000e-06]
Evaluation Classifier @ Epoch 60: 100% 4/4 [00:00<00:00,  4.04it/s, acc1=60.815, acc2=80.420, loss=1.075]
Training Classifier @ Epoch 61: 100% 43/43 [00:08<00:00,  5.20it/s, acc1=59.854, acc2=79.613, loss=1.115, lr=1.00000e-06]
Evaluation Classifier @ Epoch 61: 100% 4/4 [00:01<00:00,  4.00it/s, acc1=60.791, acc2=80.640, loss=1.075]
Training Classifier @ Epoch 62: 100% 43/43 [00:08<00:00,  5.20it/s, acc1=59.925, acc2=79.865, loss=1.115, lr=1.00000e-06]
Evaluation Classifier @ Epoch 62: 100% 4/4 [00:01<00:00,  3.99it/s, acc1=60.767, acc2=80.566, loss=1.075]
Training Classifier @ Epoch 63: 100% 43/43 [00:08<00:00,  5.18it/s, acc1=60.065, acc2=79.685, loss=1.114, lr=1.00000e-06]
Evaluation Classifier @ Epoch 63: 100% 4/4 [00:00<00:00,  4.05it/s, acc1=60.889, acc2=80.542, loss=1.075]
Training Classifier @ Epoch 64: 100% 43/43 [00:08<00:00,  5.21it/s, acc1=59.750, acc2=79.737, loss=1.115, lr=1.00000e-06]
Evaluation Classifier @ Epoch 64: 100% 4/4 [00:00<00:00,  4.17it/s, acc1=60.767, acc2=80.518, loss=1.075]
Training Classifier @ Epoch 65: 100% 43/43 [00:08<00:00,  5.20it/s, acc1=60.054, acc2=79.658, loss=1.113, lr=1.00000e-06]
Evaluation Classifier @ Epoch 65: 100% 4/4 [00:00<00:00,  4.12it/s, acc1=60.791, acc2=80.664, loss=1.075]
Training Classifier @ Epoch 66: 100% 43/43 [00:08<00:00,  5.17it/s, acc1=59.829, acc2=79.656, loss=1.114, lr=1.00000e-06]
Evaluation Classifier @ Epoch 66: 100% 4/4 [00:01<00:00,  3.94it/s, acc1=60.864, acc2=80.469, loss=1.074]
Training Classifier @ Epoch 67: 100% 43/43 [00:08<00:00,  5.20it/s, acc1=59.820, acc2=79.706, loss=1.115, lr=1.00000e-06]
Evaluation Classifier @ Epoch 67: 100% 4/4 [00:00<00:00,  4.04it/s, acc1=60.767, acc2=80.542, loss=1.074]
Training Classifier @ Epoch 68: 100% 43/43 [00:08<00:00,  5.14it/s, acc1=59.702, acc2=79.797, loss=1.118, lr=1.00000e-06]
Evaluation Classifier @ Epoch 68: 100% 4/4 [00:01<00:00,  3.87it/s, acc1=60.718, acc2=80.591, loss=1.074]
Training Classifier @ Epoch 69: 100% 43/43 [00:08<00:00,  5.14it/s, acc1=59.786, acc2=79.881, loss=1.115, lr=1.00000e-06]
Evaluation Classifier @ Epoch 69: 100% 4/4 [00:00<00:00,  4.13it/s, acc1=60.889, acc2=80.469, loss=1.074]
Training Classifier @ Epoch 70: 100% 43/43 [00:08<00:00,  5.14it/s, acc1=60.056, acc2=79.762, loss=1.114, lr=1.00000e-06]
Evaluation Classifier @ Epoch 70: 100% 4/4 [00:00<00:00,  4.12it/s, acc1=60.864, acc2=80.469, loss=1.075]
Training Classifier @ Epoch 71: 100% 43/43 [00:08<00:00,  5.20it/s, acc1=59.745, acc2=79.672, loss=1.116, lr=1.00000e-06]
Evaluation Classifier @ Epoch 71: 100% 4/4 [00:01<00:00,  4.00it/s, acc1=60.840, acc2=80.591, loss=1.074]
Training Classifier @ Epoch 72: 100% 43/43 [00:08<00:00,  5.14it/s, acc1=60.002, acc2=79.624, loss=1.117, lr=1.00000e-06]
Evaluation Classifier @ Epoch 72: 100% 4/4 [00:00<00:00,  4.15it/s, acc1=60.742, acc2=80.688, loss=1.075]
Training Classifier @ Epoch 73: 100% 43/43 [00:08<00:00,  5.17it/s, acc1=59.863, acc2=79.658, loss=1.115, lr=1.00000e-06]
Evaluation Classifier @ Epoch 73: 100% 4/4 [00:00<00:00,  4.05it/s, acc1=60.693, acc2=80.542, loss=1.075]
Training Classifier @ Epoch 74: 100% 43/43 [00:08<00:00,  5.17it/s, acc1=59.904, acc2=79.824, loss=1.115, lr=1.00000e-06]
Evaluation Classifier @ Epoch 74: 100% 4/4 [00:00<00:00,  4.09it/s, acc1=60.693, acc2=80.322, loss=1.075]
Training Classifier @ Epoch 75: 100% 43/43 [00:08<00:00,  5.15it/s, acc1=59.981, acc2=79.912, loss=1.112, lr=1.00000e-06]
Evaluation Classifier @ Epoch 75: 100% 4/4 [00:00<00:00,  4.10it/s, acc1=60.913, acc2=80.591, loss=1.074]
Training Classifier @ Epoch 76: 100% 43/43 [00:08<00:00,  5.10it/s, acc1=59.888, acc2=79.635, loss=1.114, lr=1.00000e-06]
Evaluation Classifier @ Epoch 76: 100% 4/4 [00:01<00:00,  3.89it/s, acc1=60.767, acc2=80.518, loss=1.074]
Training Classifier @ Epoch 77: 100% 43/43 [00:08<00:00,  5.00it/s, acc1=60.063, acc2=79.971, loss=1.114, lr=1.00000e-06]
Evaluation Classifier @ Epoch 77: 100% 4/4 [00:01<00:00,  3.91it/s, acc1=60.889, acc2=80.542, loss=1.074]
Training Classifier @ Epoch 78: 100% 43/43 [00:08<00:00,  5.10it/s, acc1=59.972, acc2=79.801, loss=1.115, lr=1.00000e-06]
Evaluation Classifier @ Epoch 78: 100% 4/4 [00:00<00:00,  4.04it/s, acc1=60.791, acc2=80.469, loss=1.074]
Training Classifier @ Epoch 79: 100% 43/43 [00:08<00:00,  5.14it/s, acc1=59.956, acc2=79.801, loss=1.113, lr=1.00000e-06]
Evaluation Classifier @ Epoch 79: 100% 4/4 [00:00<00:00,  4.10it/s, acc1=60.815, acc2=80.420, loss=1.074]
(Epoch: 79) > Model Saved.
Training Classifier @ Epoch 80: 100% 43/43 [00:08<00:00,  5.03it/s, acc1=59.743, acc2=79.556, loss=1.116, lr=1.00000e-06]
Evaluation Classifier @ Epoch 80: 100% 4/4 [00:01<00:00,  3.95it/s, acc1=60.742, acc2=80.518, loss=1.074]
Training Classifier @ Epoch 81: 100% 43/43 [00:08<00:00,  5.12it/s, acc1=59.816, acc2=79.769, loss=1.114, lr=1.00000e-06]
Evaluation Classifier @ Epoch 81: 100% 4/4 [00:01<00:00,  3.90it/s, acc1=60.718, acc2=80.493, loss=1.074]
Training Classifier @ Epoch 82: 100% 43/43 [00:08<00:00,  5.04it/s, acc1=59.870, acc2=79.808, loss=1.113, lr=1.00000e-06]
Evaluation Classifier @ Epoch 82: 100% 4/4 [00:00<00:00,  4.24it/s, acc1=60.815, acc2=80.322, loss=1.074]
Training Classifier @ Epoch 83: 100% 43/43 [00:08<00:00,  5.09it/s, acc1=59.557, acc2=79.667, loss=1.117, lr=1.00000e-06]
Evaluation Classifier @ Epoch 83: 100% 4/4 [00:00<00:00,  4.12it/s, acc1=60.669, acc2=80.493, loss=1.074]
Training Classifier @ Epoch 84: 100% 43/43 [00:08<00:00,  5.19it/s, acc1=59.643, acc2=79.797, loss=1.115, lr=1.00000e-06]
Evaluation Classifier @ Epoch 84: 100% 4/4 [00:00<00:00,  4.06it/s, acc1=60.767, acc2=80.640, loss=1.074]
Training Classifier @ Epoch 85: 100% 43/43 [00:08<00:00,  5.04it/s, acc1=59.822, acc2=79.901, loss=1.113, lr=1.00000e-06]
Evaluation Classifier @ Epoch 85: 100% 4/4 [00:01<00:00,  4.00it/s, acc1=60.864, acc2=80.591, loss=1.074]
Training Classifier @ Epoch 86: 100% 43/43 [00:08<00:00,  5.15it/s, acc1=59.836, acc2=79.899, loss=1.114, lr=1.00000e-06]
Evaluation Classifier @ Epoch 86: 100% 4/4 [00:01<00:00,  4.00it/s, acc1=60.815, acc2=80.518, loss=1.075]
Training Classifier @ Epoch 87: 100% 43/43 [00:08<00:00,  5.17it/s, acc1=59.918, acc2=79.715, loss=1.115, lr=1.00000e-06]
Evaluation Classifier @ Epoch 87: 100% 4/4 [00:01<00:00,  3.94it/s, acc1=60.889, acc2=80.396, loss=1.074]
Training Classifier @ Epoch 88: 100% 43/43 [00:08<00:00,  5.12it/s, acc1=59.893, acc2=79.706, loss=1.117, lr=1.00000e-06]
Evaluation Classifier @ Epoch 88: 100% 4/4 [00:00<00:00,  4.13it/s, acc1=60.791, acc2=80.518, loss=1.074]
Training Classifier @ Epoch 89: 100% 43/43 [00:08<00:00,  5.09it/s, acc1=60.020, acc2=79.849, loss=1.112, lr=1.00000e-06]
Evaluation Classifier @ Epoch 89: 100% 4/4 [00:01<00:00,  3.98it/s, acc1=60.742, acc2=80.493, loss=1.074]
Training Classifier @ Epoch 90: 100% 43/43 [00:08<00:00,  5.20it/s, acc1=59.802, acc2=79.762, loss=1.116, lr=1.00000e-06]
Evaluation Classifier @ Epoch 90: 100% 4/4 [00:01<00:00,  3.97it/s, acc1=60.938, acc2=80.542, loss=1.074]
Training Classifier @ Epoch 91: 100% 43/43 [00:08<00:00,  5.15it/s, acc1=59.845, acc2=79.828, loss=1.114, lr=1.00000e-06]
Evaluation Classifier @ Epoch 91: 100% 4/4 [00:00<00:00,  4.06it/s, acc1=60.791, acc2=80.640, loss=1.074]
Training Classifier @ Epoch 92: 100% 43/43 [00:08<00:00,  5.14it/s, acc1=59.759, acc2=79.747, loss=1.116, lr=1.00000e-06]
Evaluation Classifier @ Epoch 92: 100% 4/4 [00:00<00:00,  4.14it/s, acc1=60.767, acc2=80.469, loss=1.074]
Training Classifier @ Epoch 93: 100% 43/43 [00:08<00:00,  5.11it/s, acc1=59.727, acc2=79.728, loss=1.116, lr=1.00000e-06]
Evaluation Classifier @ Epoch 93: 100% 4/4 [00:00<00:00,  4.03it/s, acc1=60.718, acc2=80.371, loss=1.074]
Training Classifier @ Epoch 94: 100% 43/43 [00:08<00:00,  5.16it/s, acc1=60.036, acc2=79.701, loss=1.117, lr=1.00000e-06]
Evaluation Classifier @ Epoch 94: 100% 4/4 [00:01<00:00,  3.99it/s, acc1=60.913, acc2=80.493, loss=1.074]
Training Classifier @ Epoch 95: 100% 43/43 [00:08<00:00,  5.16it/s, acc1=59.997, acc2=79.642, loss=1.114, lr=1.00000e-06]
Evaluation Classifier @ Epoch 95: 100% 4/4 [00:00<00:00,  4.03it/s, acc1=60.693, acc2=80.591, loss=1.074]
Training Classifier @ Epoch 96: 100% 43/43 [00:08<00:00,  5.23it/s, acc1=59.961, acc2=79.601, loss=1.115, lr=1.00000e-06]
Evaluation Classifier @ Epoch 96: 100% 4/4 [00:01<00:00,  3.89it/s, acc1=60.815, acc2=80.396, loss=1.074]
Training Classifier @ Epoch 97: 100% 43/43 [00:08<00:00,  5.02it/s, acc1=59.791, acc2=79.683, loss=1.116, lr=1.00000e-06]
Evaluation Classifier @ Epoch 97: 100% 4/4 [00:00<00:00,  4.00it/s, acc1=60.791, acc2=80.298, loss=1.074]
Training Classifier @ Epoch 98: 100% 43/43 [00:08<00:00,  5.13it/s, acc1=59.904, acc2=79.649, loss=1.115, lr=1.00000e-06]
Evaluation Classifier @ Epoch 98: 100% 4/4 [00:00<00:00,  4.13it/s, acc1=60.693, acc2=80.469, loss=1.074]
Training Classifier @ Epoch 99: 100% 43/43 [00:08<00:00,  5.19it/s, acc1=59.684, acc2=79.747, loss=1.114, lr=1.00000e-06]
Evaluation Classifier @ Epoch 99: 100% 4/4 [00:00<00:00,  4.04it/s, acc1=60.645, acc2=80.591, loss=1.074]
(Epoch: 99) > Model Saved.
Evaluation Classifier: 100% 9/9 [00:01<00:00,  4.55it/s, acc1=59.961, acc2=79.709, loss=1.106]
[ ]
